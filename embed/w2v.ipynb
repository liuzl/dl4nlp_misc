{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用gensim来体验word2vec \n",
    "\n",
    "[docs](https://radimrehurek.com/gensim/auto_examples/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "# wv = api.load('word2vec-google-news-300') #1662.8MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练自己的模型\n",
    "\n",
    "使用政府工作报告和五年规划的语料做训练\n",
    "\n",
    "### 获取语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import hashlib\n",
    "\n",
    "def cache_dir():\n",
    "    work_dir = \"./.cache\"\n",
    "    if not os.path.isdir(work_dir):\n",
    "        os.makedirs(work_dir)\n",
    "    return work_dir\n",
    "\n",
    "def data_dir():\n",
    "    datadir = \"./data\"\n",
    "    if not os.path.isdir(datadir):\n",
    "        os.makedirs(datadir)\n",
    "    return datadir\n",
    "\n",
    "def get(url, cache=True, force=False):\n",
    "    md5 = hashlib.md5(url.encode('utf-8')).hexdigest()\n",
    "    f = \"%s/%s\" % (cache_dir(), md5)\n",
    "    if cache and not force and os.path.isfile(f):\n",
    "        return open(f, \"rb\").read()\n",
    "    content = requests.get(url).content\n",
    "    if cache:\n",
    "        open(f,\"wb\").write(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "import lxml.html\n",
    "def crawl_report_list():\n",
    "    '''\n",
    "    抓取政府工作报告列表\n",
    "    http://www.gov.cn/guoqing/2006-02/16/content_2616810.htm\n",
    "    '''\n",
    "    content = get(\"http://www.gov.cn/guoqing/2006-02/16/content_2616810.htm\")\n",
    "    if content is None: return []\n",
    "    doc = lxml.html.document_fromstring(content)\n",
    "    return doc.xpath(\"*//td//a/@href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_plan_list():\n",
    "    return ['http://www.npc.gov.cn/wxzl/gongbao/2000-12/26/content_5001764.htm', #八五\n",
    "            'http://www.npc.gov.cn/wxzl/gongbao/2000-12/28/content_5002538.htm',\n",
    "            'http://www.npc.gov.cn/wxzl/gongbao/2001-01/02/content_5003506.htm',\n",
    "            'http://www.npc.gov.cn/wxzl/gongbao/2001-03/19/content_5134505.htm',\n",
    "            'http://www.gov.cn/ztzl/2006-03/16/content_228841.htm',\n",
    "            'http://www.gov.cn/2011lh/content_1825838.htm',\n",
    "            'http://politics.people.com.cn/n/2015/1103/c1001-27772701-2.html', #十三五\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = crawl_report_list() + crawl_plan_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyce3\n",
    "\n",
    "for url in urls:\n",
    "    enc, t, title, text, next_url = pyce3.parse(url, get(url))\n",
    "    text = text.strip()\n",
    "    title = title.strip()\n",
    "    if len(text) > 0 and len(title) > 0:\n",
    "        open(data_dir()+\"/%s.txt\"%title, \"w\").write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(data_dir() + \"/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(files[15]).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = re.sub(pyce3.RE_TAG, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "lines = [unicodedata.normalize('NFKC', x.strip()) for x in text.split('\\n') if x.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uniseg.wordbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['—',\n",
       " '—',\n",
       " '2007',\n",
       " '年',\n",
       " '3',\n",
       " '月',\n",
       " '5',\n",
       " '日',\n",
       " '在',\n",
       " '第',\n",
       " '十',\n",
       " '届',\n",
       " '全',\n",
       " '国',\n",
       " '人',\n",
       " '民',\n",
       " '代',\n",
       " '表',\n",
       " '大',\n",
       " '会',\n",
       " '第',\n",
       " '五',\n",
       " '次',\n",
       " '会',\n",
       " '议',\n",
       " '上']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in uniseg.wordbreak.words(lines[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
