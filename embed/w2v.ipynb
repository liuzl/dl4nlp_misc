{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用gensim来体验word2vec \n",
    "\n",
    "[docs](https://radimrehurek.com/gensim/auto_examples/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "# wv = api.load('word2vec-google-news-300') #1662.8MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练自己的模型\n",
    "\n",
    "使用政府工作报告和五年规划的语料做训练\n",
    "\n",
    "### 获取语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import hashlib\n",
    "\n",
    "def cache_dir():\n",
    "    work_dir = \"./.cache\"\n",
    "    if not os.path.isdir(work_dir):\n",
    "        os.makedirs(work_dir)\n",
    "    return work_dir\n",
    "\n",
    "def data_dir():\n",
    "    datadir = \"./data\"\n",
    "    if not os.path.isdir(datadir):\n",
    "        os.makedirs(datadir)\n",
    "    return datadir\n",
    "\n",
    "def get(url, cache=True, force=False):\n",
    "    md5 = hashlib.md5(url.encode('utf-8')).hexdigest()\n",
    "    f = \"%s/%s\" % (cache_dir(), md5)\n",
    "    if cache and not force and os.path.isfile(f):\n",
    "        return open(f, \"rb\").read()\n",
    "    content = requests.get(url).content\n",
    "    if cache:\n",
    "        open(f,\"wb\").write(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "import lxml.html\n",
    "def crawl_report_list():\n",
    "    '''\n",
    "    抓取政府工作报告列表\n",
    "    http://www.gov.cn/guoqing/2006-02/16/content_2616810.htm\n",
    "    '''\n",
    "    content = get(\"http://www.gov.cn/guoqing/2006-02/16/content_2616810.htm\")\n",
    "    if content is None: return []\n",
    "    doc = lxml.html.document_fromstring(content)\n",
    "    return doc.xpath(\"*//td//a/@href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_plan_list():\n",
    "    return ['http://www.npc.gov.cn/wxzl/gongbao/2000-12/26/content_5001764.htm', #八五\n",
    "            'http://www.npc.gov.cn/wxzl/gongbao/2000-12/28/content_5002538.htm',\n",
    "            'http://www.npc.gov.cn/wxzl/gongbao/2001-01/02/content_5003506.htm',\n",
    "            'http://www.npc.gov.cn/wxzl/gongbao/2001-03/19/content_5134505.htm',\n",
    "            'http://www.gov.cn/ztzl/2006-03/16/content_228841.htm',\n",
    "            'http://www.gov.cn/2011lh/content_1825838.htm',\n",
    "            'http://politics.people.com.cn/n/2015/1103/c1001-27772701-2.html', #十三五\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = crawl_report_list() + crawl_plan_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyce3\n",
    "\n",
    "for url in urls:\n",
    "    enc, t, title, text, next_url = pyce3.parse(url, get(url))\n",
    "    text = text.strip()\n",
    "    title = title.strip()\n",
    "    if len(text) > 0 and len(title) > 0:\n",
    "        open(data_dir()+\"/%s.txt\"%title, \"w\").write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(data_dir() + \"/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(files[15]).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = re.sub(pyce3.RE_TAG, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import uniseg.wordbreak\n",
    "import uniseg.sentencebreak\n",
    "olines = [unicodedata.normalize('NFKC', x.strip()) for x in text.split('\\n') if x.strip() != '']\n",
    "lines = [unicodedata.normalize('NFKC', x.strip()) for x in uniseg.sentencebreak.sentences(text) if x.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x for x in uniseg.wordbreak.words(lines[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus(files):\n",
    "    ret = []\n",
    "    for f in files:\n",
    "        text = re.sub(pyce3.RE_TAG, '', open(f).read())\n",
    "        lines = [unicodedata.normalize('NFKC', x.strip())\\\n",
    "                 #for x in uniseg.sentencebreak.sentences(text)\\\n",
    "                 for x in text.split('\\n')\\\n",
    "                 if x.strip() != '']\n",
    "        for line in lines:\n",
    "            ret.append([x for x in uniseg.wordbreak.words(line)])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = corpus(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996\n",
      "年\n",
      "政\n",
      "府\n",
      "工\n",
      "作\n",
      "报\n",
      "告\n",
      "关\n",
      "于\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(model.wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('它', 0.7728102207183838),\n",
       " ('他', 0.655555009841919),\n",
       " ('家', 0.5821338891983032),\n",
       " ('祖', 0.549433708190918),\n",
       " ('尤', 0.39443439245224),\n",
       " ('帝', 0.38537460565567017),\n",
       " ('际', 0.3738643229007721),\n",
       " ('全', 0.3556334376335144),\n",
       " ('内', 0.35547029972076416),\n",
       " ('中', 0.3451741933822632)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('我')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词语挖掘\n",
    "\n",
    "通过word2phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = Phrases(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1996', '年', '政_府', '工', '作', '报_告']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[texts[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
